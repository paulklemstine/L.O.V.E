<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DMT Audio Reactive Feed</title>
    <style>
        body,
        html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            background-color: #000;
            font-family: 'Courier New', Courier, monospace;
        }

        /* The WebGL Canvas */
        canvas {
            display: block;
            width: 100%;
            height: 100%;
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1;
        }

        /* Interaction Overlay (Start Button) */
        #start-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.85);
            z-index: 100;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            color: #00e5ff;
            text-align: center;
            transition: opacity 1s ease;
        }

        button {
            background: transparent;
            color: #00e5ff;
            border: 2px solid #00e5ff;
            padding: 15px 30px;
            font-size: 1.2rem;
            font-family: inherit;
            cursor: pointer;
            text-transform: uppercase;
            letter-spacing: 3px;
            transition: all 0.3s;
            margin-top: 20px;
        }

        button:hover {
            background: #00e5ff;
            color: #000;
            box-shadow: 0 0 20px #00e5ff;
        }

        /* The Content Overlay */
        #content-layer {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 10;
            width: 90%;
            max-width: 550px;
            pointer-events: none;
            /* Allows clicks to pass, but we'll re-enable for card */
        }

        /* Glassmorphism card */
        .glass-card {
            background: rgba(0, 0, 0, 0.4);
            backdrop-filter: blur(12px);
            -webkit-backdrop-filter: blur(12px);
            border: 1px solid rgba(255, 255, 255, 0.15);
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 4px 30px rgba(0, 0, 0, 0.5);
            transition: opacity 1s ease-in-out;
            opacity: 0;
            color: #fff;
            pointer-events: auto;
            /* Enable scrolling/clicking on the card */
            max-height: 80vh;
            overflow-y: auto;
            scrollbar-width: thin;
        }

        .handle {
            font-size: 0.9rem;
            color: #00e5ff;
            margin-bottom: 0.8rem;
            text-shadow: 0 0 10px rgba(0, 229, 255, 0.6);
            text-transform: uppercase;
            letter-spacing: 2px;
            border-bottom: 1px solid rgba(0, 229, 255, 0.3);
            padding-bottom: 10px;
        }

        .post-content {
            font-size: 1.1rem;
            line-height: 1.5;
            color: #e0e0e0;
            margin-bottom: 1rem;
        }

        /* Image Styling */
        .post-image-container {
            width: 100%;
            margin-top: 15px;
            border-radius: 8px;
            overflow: hidden;
            display: none;
            /* Hidden by default */
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .post-image {
            width: 100%;
            height: auto;
            display: block;
        }

        .meta {
            margin-top: 1.5rem;
            font-size: 0.75rem;
            color: rgba(255, 255, 255, 0.5);
            text-align: right;
        }

        /* Custom Scrollbar for the card */
        .glass-card::-webkit-scrollbar {
            width: 6px;
        }

        .glass-card::-webkit-scrollbar-track {
            background: rgba(0, 0, 0, 0.1);
        }

        .glass-card::-webkit-scrollbar-thumb {
            background: rgba(0, 229, 255, 0.3);
            border-radius: 3px;
        }
    </style>
</head>

<body>

    <!-- WebGL Canvas -->
    <canvas id="glcanvas"></canvas>

    <!-- Start Overlay -->
    <div id="start-overlay">
        <h1>NEURAL HANDSHAKE REQUIRED</h1>
        <p>Microphone access needed for audio reactivity</p>
        <button id="start-btn">INITIATE</button>
    </div>

    <!-- Feed Content -->
    <div id="content-layer">
        <div id="post-container" class="glass-card">
            <div class="handle">@e-v-l-o-v-e.bsky.social</div>
            <div class="post-content" id="post-text">Fetching transmission...</div>
            <div class="post-image-container" id="img-container">
                <img id="post-image" class="post-image" alt="Post attachment" />
            </div>
            <div class="meta" id="post-date"></div>
        </div>
    </div>

    <!-- WEBGL SHADERS -->
    <script id="fragShader" type="x-shader/x-fragment">
        #ifdef GL_ES
        precision mediump float;
        #endif

        uniform float u_time;
        uniform vec2 u_resolution;
        
        // Audio Uniforms (0.0 to 1.0)
        uniform float u_low;  // Bass
        uniform float u_mid;  // Mids
        uniform float u_high; // Treble

        // Palette function
        vec3 palette( in float t ) {
            // A trippy palette: contrasty and colorful
            vec3 a = vec3(0.5, 0.5, 0.5);
            vec3 b = vec3(0.5, 0.5, 0.5);
            vec3 c = vec3(1.0, 1.0, 1.0);
            // Shift phase based on high frequencies
            vec3 d = vec3(0.263, 0.416, 0.557) + (u_high * 0.2); 
            return a + b*cos( 6.28318*(c*t+d) );
        }

        // 2D Rotation
        mat2 rot(float a) {
            float s = sin(a);
            float c = cos(a);
            return mat2(c, -s, s, c);
        }

        void main() {
            vec2 uv = (gl_FragCoord.xy * 2.0 - u_resolution.xy) / u_resolution.y;
            vec2 uv0 = uv;
            vec3 finalColor = vec3(0.0);

            // Audio Reactivity modifiers
            float bassZoom = 1.0 + (u_low * 0.5); // Bass zooms the fractal out/in
            float midIter = (u_mid * 0.5);        // Mids add complexity
            
            for (float i = 0.0; i < 4.0; i++) {
                // Fractal space folding
                uv = fract(uv * (1.5 + midIter * 0.1)) - 0.5;

                // Distance calculation
                float d = length(uv) * exp(-length(uv0));

                // Color calculation based on spatial position + time + treble
                vec3 col = palette(length(uv0) + i*.4 + u_time*.4 + u_high*0.5);

                // The "Breathing" Sinusoid
                // Bass modifies the frequency of the rings
                d = sin(d * (8. + u_low * 10.) + u_time) / 8.;
                d = abs(d);
                
                // Neon Glow
                // Inverse power function. Bass intensifies the glow.
                // pow(0.01 / d, 1.2) is standard. We reduce the divisor 1.2 based on bass to make it "sharper" or "bloomy"
                float glow = pow(0.01 / d, 1.2 - (u_low * 0.4));
                
                finalColor += col * glow;
            }
             
            // Kaleidoscopic Rotation based on time
            uv0 *= rot(u_time * 0.1);
            
            // Output
            gl_FragColor = vec4(finalColor, 1.0);
        }
    </script>

    <script id="vertShader" type="x-shader/x-vertex">
        attribute vec2 a_position;
        void main() {
            gl_Position = vec4(a_position, 0.0, 1.0);
        }
    </script>

    <script>
        // --- CONFIGURATION ---
        const CONFIG = {
            handle: 'e-v-l-o-v-e.bsky.social',
            apiBase: 'https://public.api.bsky.app/xrpc'
        };

        // --- GLOBAL STATE ---
        let audioContext, analyser, dataArray;
        let audioValues = { low: 0, mid: 0, high: 0 };
        let isAudioActive = false;

        // --- PART 1: AUDIO SYSTEM ---
        async function initAudio() {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256; // Defines data resolution (128 bins)

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);

                dataArray = new Uint8Array(analyser.frequencyBinCount);
                isAudioActive = true;

                // Hide overlay
                const overlay = document.getElementById('start-overlay');
                overlay.style.opacity = '0';
                setTimeout(() => overlay.remove(), 1000);

            } catch (e) {
                console.error("Audio Init Failed:", e);
                alert("Microphone access denied. Visualization will run in auto-mode.");
                // Remove overlay anyway to show the visual
                document.getElementById('start-overlay').remove();
            }
        }

        function analyzeAudio() {
            if (!isAudioActive) return;

            analyser.getByteFrequencyData(dataArray);

            // Simple frequency banding
            // fftSize 256 = 128 bins.
            // 0-4: Bass
            // 5-20: Mids
            // 21-127: Highs

            let lowSum = 0, midSum = 0, highSum = 0;

            for (let i = 0; i < 4; i++) lowSum += dataArray[i];
            for (let i = 4; i < 20; i++) midSum += dataArray[i];
            for (let i = 20; i < 128; i++) highSum += dataArray[i];

            // Normalize (0.0 - 1.0) and Smooth
            const targetLow = lowSum / (4 * 255);
            const targetMid = midSum / (16 * 255);
            const targetHigh = highSum / (108 * 255);

            // Linear interpolation for smoothness (Lerp)
            audioValues.low += (targetLow - audioValues.low) * 0.1;
            audioValues.mid += (targetMid - audioValues.mid) * 0.1;
            audioValues.high += (targetHigh - audioValues.high) * 0.1;
        }

        document.getElementById('start-btn').addEventListener('click', () => {
            initAudio();
        });


        // --- PART 2: WEBGL SYSTEM ---
        const canvas = document.getElementById("glcanvas");
        const gl = canvas.getContext("webgl");

        if (!gl) alert("WebGL not supported");

        function resize() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, canvas.width, canvas.height);
        }
        window.addEventListener("resize", resize);
        resize();

        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        const program = gl.createProgram();
        const vertShader = createShader(gl, gl.VERTEX_SHADER, document.getElementById("vertShader").text);
        const fragShader = createShader(gl, gl.FRAGMENT_SHADER, document.getElementById("fragShader").text);
        gl.attachShader(program, vertShader);
        gl.attachShader(program, fragShader);
        gl.linkProgram(program);
        gl.useProgram(program);

        // Buffer Setup
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]), gl.STATIC_DRAW);

        const positionLocation = gl.getAttribLocation(program, "a_position");
        gl.enableVertexAttribArray(positionLocation);
        gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

        // Uniform Locations
        const uTime = gl.getUniformLocation(program, "u_time");
        const uRes = gl.getUniformLocation(program, "u_resolution");
        const uLow = gl.getUniformLocation(program, "u_low");
        const uMid = gl.getUniformLocation(program, "u_mid");
        const uHigh = gl.getUniformLocation(program, "u_high");

        function render(time) {
            analyzeAudio(); // Update audio values

            time *= 0.001;
            gl.uniform1f(uTime, time);
            gl.uniform2f(uRes, canvas.width, canvas.height);

            // Pass audio data to shader
            gl.uniform1f(uLow, audioValues.low);
            gl.uniform1f(uMid, audioValues.mid);
            gl.uniform1f(uHigh, audioValues.high);

            gl.drawArrays(gl.TRIANGLES, 0, 6);
            requestAnimationFrame(render);
        }
        requestAnimationFrame(render);


        // --- PART 3: BLUESKY FEED PARSER ---
        async function fetchPost() {
            const container = document.getElementById('post-container');
            const loadingText = document.getElementById('post-text');
            const imgContainer = document.getElementById('img-container');
            const imgEl = document.getElementById('post-image');

            try {
                // Resolve Handle
                const resolveData = await fetch(`${CONFIG.apiBase}/com.atproto.identity.resolveHandle?handle=${CONFIG.handle}`).then(r => r.json());
                if (!resolveData.did) throw new Error("DID lookup failed");

                // Get Feed
                const feedData = await fetch(`${CONFIG.apiBase}/app.bsky.feed.getAuthorFeed?actor=${resolveData.did}&limit=1`).then(r => r.json());

                if (feedData.feed && feedData.feed.length > 0) {
                    const post = feedData.feed[0].post;
                    const record = post.record;

                    // 1. Text
                    document.getElementById('post-text').innerText = record.text || "(No text content)";

                    // 2. Date
                    document.getElementById('post-date').innerText = new Date(record.createdAt).toLocaleString();

                    // 3. Image Handling
                    let imageUrl = null;

                    // Case A: Standard Image Embed
                    if (post.embed && post.embed.$type === 'app.bsky.embed.images#view') {
                        if (post.embed.images && post.embed.images.length > 0) {
                            imageUrl = post.embed.images[0].fullsize;
                        }
                    }
                    // Case B: Record with Media (Quote tweets with media, etc)
                    else if (post.embed && post.embed.$type === 'app.bsky.embed.recordWithMedia#view') {
                        if (post.embed.media && post.embed.media.images && post.embed.media.images.length > 0) {
                            imageUrl = post.embed.media.images[0].fullsize;
                        }
                    }

                    if (imageUrl) {
                        imgEl.src = imageUrl;
                        imgContainer.style.display = 'block';
                    } else {
                        imgContainer.style.display = 'none';
                    }

                    // Reveal
                    container.style.opacity = '1';
                }
            } catch (err) {
                console.error("Feed Error:", err);
                loadingText.innerText = "SIGNAL LOST // RECONNECTING...";
            }
        }

        // Initial fetch and poll
        fetchPost();
        setInterval(fetchPost, 60000);

    </script>
</body>

</html>