{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulklemstine/L.O.V.E/blob/main/The_Simple_Stable_Horde_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "LfULY3uOREQq"
      },
      "outputs": [],
      "source": [
        "#@markdown #Google has asked that the worker notebook no longer be used. Come to https://discord.com/channels/781145214752129095/1050476592691957880 for more information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "68LjHhCl2VyI",
        "outputId": "314fcb96-c366-4caf-9a56-6bc172fd965a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter an API key and resubmit\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#@markdown #Latest Update: 23-7-2023 04:45â€¯PM UTC - Comfy Colab v1.6 (Fix top 1 resolving to sdxl_beta!)\n",
        "#@markdown \\\n",
        "#@markdown ## Give your worker a name\n",
        "#@markdown ##### (If you have used this before, please re-use your worker name)\n",
        "# The horde url\n",
        "horde_url = \"https://aihorde.net\"\n",
        "worker_name = \"Give your worker a cool name\" #@param {type:\"string\"}\n",
        "\n",
        "if worker_name == \"\" or worker_name == \"Give me a cool worker name\":\n",
        "  print(\"Please enter a new worker name and resubmit\")\n",
        "#@markdown \\\n",
        "#@markdown ## Enter your API key for the horde\n",
        "#@markdown ##### (If you havent got one, go to https://aihorde.net/register)\n",
        "api_key = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if api_key == \"\":\n",
        "  print(\"Please enter an API key and resubmit\")\n",
        "#@markdown \\\n",
        "\n",
        "\n",
        "#@markdown ### Choose a mode\n",
        "mode = \"Simple\" #@param [\"Simple\", \"Pick My Model\", \"Inpainter\", \"Interrogation\"]\n",
        "\n",
        "\n",
        "#@markdown *Simple Mode = No futher settings required. Press control+f9 to run all the cells to get started. \\\n",
        "#@markdown Inpainting Mode = Runs the inpainter model and stable_diffusion* \\\n",
        "#@markdown *Interrogation Mode = Fulfils requests for captions, tags and nsfw* \\\n",
        "#@markdown *Pick A Model Mode = Runs only the model selected below* \\\n",
        "#@markdown ##Run this cell to see a list of models\n",
        "#@markdown - *'top 1' automatically selects the most popular model (This is the default for simple mode)*\n",
        "#@markdown - *first three models in the list are models with most images generated in a month*\n",
        "\n",
        "import requests\n",
        "\n",
        "models_url = \"https://raw.githubusercontent.com/Haidra-Org/AI-Horde-image-model-reference/main/stable_diffusion.json\"\n",
        "if \"all_models\" not in locals():\n",
        "  all_models = requests.get(models_url).json()\n",
        "  model_stats = requests.get(\"https://aihorde.net/api/v2/stats/img/models\").json()\n",
        "  for name, count in model_stats[\"month\"].items():\n",
        "    if name in all_models:\n",
        "      if name == \"SDXL_beta::stability.ai#6901\":\n",
        "        continue\n",
        "      all_models[name][\"count\"] = count\n",
        "  inpainting_models = {\n",
        "      name: params.get(\"count\", 0) for name, params in all_models.items()\n",
        "      if params[\"inpainting\"]}\n",
        "  normal_models = {\n",
        "      name: params.get(\"count\", 0) for name, params in all_models.items()\n",
        "      if not params[\"inpainting\"]}\n",
        "\n",
        "by_popularity = sorted(normal_models.items(), key=lambda x: -x[1])\n",
        "\n",
        "if mode == \"Inpainter\":\n",
        "  by_popularity = sorted(inpainting_models.items(), key=lambda x: -x[1])\n",
        "  model_list = [name for name, count in by_popularity]\n",
        "if mode == \"Pick My Model\":\n",
        "  popular = [name for name, count in by_popularity[:3]]\n",
        "  rest = [name for name, count in sorted(by_popularity[3:], key=lambda x: x[0].lower())]\n",
        "  model_list = [\"top 1\"] + popular + rest\n",
        "if 'pick_my_model' in locals():\n",
        "  model_list = [locals().get('pick_my_model')] + model_list\n",
        "\n",
        "from markdown import markdown\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HTML, interactive\n",
        "\n",
        "def model_chooser(model):\n",
        "  global pick_my_model\n",
        "  pick_my_model = model\n",
        "\n",
        "if mode == \"Pick My Model\":\n",
        "  pick_normal_model_widget = interactive(model_chooser, model=model_list)\n",
        "  display(HTML(markdown(\"# Pick a model\")))\n",
        "  display(pick_normal_model_widget)\n",
        "if mode == \"Inpainter\":\n",
        "  pick_inpainting_model_widget = interactive(model_chooser, model=model_list)\n",
        "  display(HTML(markdown(\"# Pick a model\")))\n",
        "  display(pick_inpainting_model_widget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "TJu1A8cugdrT"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define configuration options\n",
        "\n",
        "\n",
        "#@markdown ### Show Logs\n",
        "Show_Logs = True #@param {type:\"boolean\"}\n",
        "#@markdown *If ticked, this will show a log in the output console for each generation.  If unticked, a flashing cursor will appear until an error occurs and the log is in the AI-Horde-Worker/logs folder*\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown ## **When finished, press control+f9 to run all the cells, or use the menu at the top (Runtime -> Run all).**\n",
        "#@markdown ### It will take about 5 minutes for the worker to start processing jobs. Check in to make sure no errors are being encountered every so often.\n",
        "if mode == \"Inpainter\":\n",
        "  allow_painting = True\n",
        "  dynamic_models = False\n",
        "  max_power = 22\n",
        "  models_to_load = [f\"{pick_my_model}\"]\n",
        "  models_to_skip = [\"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "  allow_post_processing = False\n",
        "\n",
        "elif mode == \"Pick My Model\":\n",
        "  allow_painting = False\n",
        "  dynamic_models = False\n",
        "  max_power = 22\n",
        "  if pick_my_model == \"top 1\":\n",
        "    models_to_load = [f\"{by_popularity[0][0]}\"]\n",
        "  else:\n",
        "    models_to_load = [f\"{pick_my_model}\"]\n",
        "  models_to_skip = [\"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "  allow_post_processing = False\n",
        "\n",
        "else:\n",
        "  allow_painting = False\n",
        "  dynamic_models = False\n",
        "  max_power = 22\n",
        "  models_to_load = [f\"{by_popularity[0][0]}\"]\n",
        "  models_to_skip = [\"stable_diffusion_inpainting\", \"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "  allow_post_processing = False\n",
        "\n",
        "###  IGNORE FROM HERE UNLESS YOU KNOW WHAT YOU ARE DOING ###\n",
        "enable_loras = False\n",
        "priority_usernames = []\n",
        "max_threads = 1\n",
        "nsfw = True\n",
        "censor_nsfw = False\n",
        "blacklist = []\n",
        "censorlist = []\n",
        "allow_img2img = True\n",
        "allow_controlnet = False\n",
        "allow_unsafe_ip = True\n",
        "number_of_dynamic_models = 0\n",
        "max_models_to_download = 12\n",
        "forms = [\"caption\",\"nsfw\",\"interrogation\",\"post-process\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "F9UlsTER9tY4",
        "outputId": "cba1cf12-0f0a-43f9-cb40-df1c10da833d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'AI-Horde-Worker'...\n",
            "remote: Enumerating objects: 4806, done.\u001b[K\n",
            "remote: Counting objects: 100% (1324/1324), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 4806 (delta 1228), reused 1162 (delta 1160), pack-reused 3482 (from 2)\u001b[K\n",
            "Receiving objects: 100% (4806/4806), 11.19 MiB | 17.65 MiB/s, done.\n",
            "Resolving deltas: 100% (3330/3330), done.\n",
            "/content/AI-Horde-Worker\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Ignoring windows-curses: markers 'sys_platform == \"win32\"' don't match your environment\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.1 (from versions: 2.2.0, 2.2.0+cu118, 2.2.1, 2.2.1+cu118, 2.2.2, 2.2.2+cu118, 2.3.0, 2.3.0+cu118, 2.3.1, 2.3.1+cu118, 2.4.0, 2.4.0+cu118, 2.4.1, 2.4.1+cu118, 2.5.0, 2.5.0+cu118, 2.5.1, 2.5.1+cu118, 2.6.0, 2.6.0+cu118, 2.7.0, 2.7.0+cu118, 2.7.1, 2.7.1+cu118, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@markdown # Download and Install Stable Diffusion for Stable Horde\n",
        "#@markdown This takes ~5 minutes - please ignore any red errors telling you to restart the runtime after installing a new version of something\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "if 'install_completed' not in locals():\n",
        "    !git clone https://github.com/db0/AI-Horde-Worker.git\n",
        "\n",
        "    %cd /content/AI-Horde-Worker\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "install_completed=True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "MUosNcNE3TPy",
        "outputId": "2b08025b-659e-48e9-a70a-bae675e28fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-Horde-Worker\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/AI-Horde-Worker/bridge_stable_diffusion.py\", line 11, in <module>\n",
            "    import hordelib\n",
            "ModuleNotFoundError: No module named 'hordelib'\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Stable Horde worker\n",
        "#@markdown For maximum runtime, leave this browser tab running and clear the logs every 15-30 mins by hitting the X in the top left corner of the logs (will appear when hovering over the three dots)\n",
        "import os\n",
        "\n",
        "%cd /content/AI-Horde-Worker\n",
        "\n",
        "!rm -rf bridgeData.yaml\n",
        "\n",
        "from yaml import load, dump\n",
        "def make_yaml_sublist(list_to_convert: list[str]):\n",
        "  sublist_yaml = dump(list_to_convert)\n",
        "  sublist_yaml = \"\\n\" + sublist_yaml\n",
        "  return sublist_yaml\n",
        "\n",
        "if \"api_key\" not in locals():\n",
        "  print()\n",
        "  print(\"*\" * 80)\n",
        "  print(\"ERROR: You haven't set an API key... double check the first cell at the top of the page.\")\n",
        "  print(\"*\" * 80)\n",
        "  print()\n",
        "\n",
        "data = f\"\"\"horde_url: \"{horde_url}\"\n",
        "api_key: \"{api_key}\"\n",
        "priority_usernames: []\n",
        "max_threads: {max_threads}\n",
        "queue_size: 1\n",
        "require_upfront_kudos: false\n",
        "dreamer_name: \"{worker_name}\"\n",
        "max_power: {max_power}\n",
        "nsfw: {nsfw.__str__().lower()}\n",
        "censor_nsfw: false\n",
        "blacklist: {blacklist}\n",
        "censorlist: {censorlist}\n",
        "allow_img2img: {allow_img2img.__str__().lower()}\n",
        "allow_painting: {allow_painting.__str__().lower()}\n",
        "allow_unsafe_ip: true\n",
        "allow_post_processing: {allow_post_processing.__str__().lower()}\n",
        "allow_controlnet: false\n",
        "dynamic_models: false\n",
        "number_of_dynamic_models: 0\n",
        "max_models_to_download: 10\n",
        "stats_output_frequency: 30\n",
        "cache_home: \"./\"\n",
        "always_download: true\n",
        "temp_dir: \"./tmp\"\n",
        "disable_terminal_ui: true\n",
        "vram_to_leave_free: \"40%\"\n",
        "ram_to_leave_free: \"80%\"\n",
        "disable_disk_cache: false\n",
        "models_to_load: {make_yaml_sublist(models_to_load)}\n",
        "models_to_skip: {make_yaml_sublist(models_to_skip)}\n",
        "forms:\n",
        "  - \"caption\"\n",
        "  - \"nsfw\"\n",
        "  - \"interrogation\"\n",
        "  - \"post-process\"\n",
        "allow_lora: {enable_loras.__str__().lower()}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"bridgeData.yaml\", \"w\") as text_file:\n",
        "  text_file.write(data)\n",
        "\n",
        "!export LOW_VRAM_MODE=0\n",
        "if mode == \"Interrogation\":\n",
        "  if Show_Logs:\n",
        "    !python bridge_alchemy.py -y\n",
        "  else:\n",
        "    print (\"Your worker has started and is running while the cursor below is flashing\")\n",
        "    !python bridge_alchemy.py -y -q\n",
        "\n",
        "else:\n",
        "  if Show_Logs:\n",
        "    !python bridge_stable_diffusion.py -y\n",
        "  else:\n",
        "    print (\"Your worker has started and is running while the cursor below is flashing\")\n",
        "    !python bridge_stable_diffusion.py -y -q"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}