import json
import subprocess
import os
import logging
from typing import Dict, Any, List
from core.state import DeepAgentState
from langchain_core.messages import AIMessage, HumanMessage

# Configure logging
logger = logging.getLogger(__name__)

class StaticAnalyzer:
    """
    Encapsulates the execution of static analysis tools.
    """
    def __init__(self):
        self.env = os.environ.copy()

    def run_ruff(self, filepath: str) -> Dict[str, Any]:
        """Runs Ruff for auto-fixing and linting."""
        # 1. Attempt Auto-Fix (Silent Improvement)
        try:
            subprocess.run(["ruff", "check", "--fix", filepath], 
                         capture_output=True, env=self.env, check=False)
            subprocess.run(["ruff", "format", filepath], 
                         capture_output=True, env=self.env, check=False)
        except FileNotFoundError:
            logger.warning("Ruff not found. Skipping auto-fix.")

        # 2. Run Check for Reporting
        try:
            result = subprocess.run(
                ["ruff", "check", "--output-format=json", filepath],
                capture_output=True, text=True, env=self.env, check=False
            )
            return {"tool": "ruff", "errors": json.loads(result.stdout)}
        except (FileNotFoundError, json.JSONDecodeError):
            return {"tool": "ruff", "errors": []}

    def run_bandit(self, filepath: str) -> Dict[str, Any]:
        """Runs Bandit for security scanning."""
        try:
            result = subprocess.run(
                ["bandit", "-f", "json", "-r", filepath],
                capture_output=True, text=True, env=self.env, check=False
            )
            # Bandit returns exit code 1 if issues found, so check=False is needed.
            data = json.loads(result.stdout)
            # Filter for HIGH severity
            high_sev = [res for res in data.get('results', []) 
                       if res['issue_severity'] == 'HIGH']
            return {"tool": "bandit", "errors": high_sev}
        except (FileNotFoundError, json.JSONDecodeError):
            return {"tool": "bandit", "errors": []}

    def run_radon(self, filepath: str) -> Dict[str, Any]:
        """Runs Radon for complexity analysis."""
        try:
            result = subprocess.run(
                ["radon", "cc", "-j", filepath],
                capture_output=True, text=True, env=self.env, check=False
            )
            data = json.loads(result.stdout)
            
            # Flatten structure and filter for Complexity > 15 (Rank C+)
            complex_blocks = []
            all_blocks = []
            for file_key, blocks in data.items():
                for block in blocks:
                    all_blocks.append(block)
                    if block['complexity'] > 15:
                        complex_blocks.append(block)

            # Log Visual Reporting for Complexity
            if all_blocks:
                avg_complexity = sum(b['complexity'] for b in all_blocks) / len(all_blocks)
                max_complexity = max(b['complexity'] for b in all_blocks)
                logger.info(f"Radon Complexity Report for {filepath}: Avg={avg_complexity:.2f}, Max={max_complexity}")
            
            return {"tool": "radon", "errors": complex_blocks}
        except (FileNotFoundError, json.JSONDecodeError):
            return {"tool": "radon", "errors": []}

async def static_analysis_node(state: DeepAgentState) -> Dict[str, Any]:
    """
    LangGraph node that runs static analysis on the latest generated code.
    """
    # 1. Extract Code
    # Assuming code is in the last message or a specific state key
    # For robust implementation, we read from the file generated by 'coder' node
    # In the current simple graph, we might not have 'working_memory' populated with file path yet.
    # We will assume the code content is in the last message if not in file.
    
    working_memory = state.get("working_memory", {})
    filepath = working_memory.get("current_file_path", "temp_script.py")
    
    # If the file doesn't exist, we might need to write the last message content to it.
    if not os.path.exists(filepath):
        # Fallback: try to write the content of the last message to a temp file
        last_msg = state["messages"][-1].content
        if "```python" in last_msg:
             # Basic extraction if it's markdown
             code = last_msg.split("```python")[1].split("```")[0].strip()
        elif "```" in last_msg:
             code = last_msg.split("```")[1].split("```")[0].strip()
        else:
             code = last_msg
             
        with open(filepath, "w") as f:
            f.write(code)

    if not os.path.exists(filepath):
        return {"messages": [HumanMessage(content="Error: File not found for analysis.")]}

    analyzer = StaticAnalyzer()
    
    # 2. Execute Tools
    ruff_res = analyzer.run_ruff(filepath)
    bandit_res = analyzer.run_bandit(filepath)
    radon_res = analyzer.run_radon(filepath)
    
    # 3. Aggregating Feedback
    feedback_lines = []
    
    # Process Bandit (Security - Blocker)
    for err in bandit_res["errors"]:
        feedback_lines.append(f"SECURITY CRITICAL (Line {err['line_number']}): {err['issue_text']} (ID: {err['test_id']}). Fix immediately.")

    # Process Radon (Complexity - Blocker)
    for err in radon_res["errors"]:
        feedback_lines.append(f"COMPLEXITY ERROR: Function '{err['name']}' has complexity {err['complexity']}. Max allowed is 15. Decompose this function.")

    # Process Ruff (Linting - Informational/Blocker if unfixable)
    # Ruff usually auto-fixes, so remaining errors are often syntax or unfixable
    for err in ruff_res["errors"]:
        feedback_lines.append(f"Syntax/Lint Error (Line {err['location']['row']}): {err['message']} (Code: {err['code']})")

    # 4. State Update Logic
    # Update iterations count to prevent infinite loops
    current_iterations = working_memory.get("analysis_iterations", 0) + 1
    
    if feedback_lines:
        # If errors exist, we reject and send feedback to Coder
        rejection_msg = "Static Analysis found the following blocking issues:\n" + "\n".join(feedback_lines)
        return {
            "messages": [HumanMessage(content=rejection_msg)],
            "working_memory": {
                **working_memory,
                "analysis_status": "failed",
                "analysis_iterations": current_iterations
            }
        }
    else:
        # If clean, we approve
        # Note: We reload the file content because Ruff might have auto-fixed/formatted it
        with open(filepath, 'r') as f:
            clean_code = f.read()
            
        return {
            "messages": [], # No new message needed if passing silently, or maybe an implementation note?
            "working_memory": {
                **working_memory,
                "analysis_status": "passed",
                "current_code_content": clean_code,
                "analysis_iterations": 0 # Reset on pass
            }
        }
