#!/usr/bin/env python3
"""
End-to-End Evolution Chain Verification (Story 5.2)

Spins up the entire stack and asks the agent to:
"Create a file named hello_world.py"

Success Conditions:
1. File exists at expected path
2. File contains print("Hello World")
3. No errors during execution

This verifies the entire chain: Intent -> Plan -> Tool -> File System
"""
import sys
import os
import asyncio
import tempfile
import shutil

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from tests.mocks.mock_llm import MockLLM, MockLLMContextManager
from core.tools import write_file
from core.nodes.reasoning import _parse_tool_calls_from_response


class EvolutionChainVerifier:
    """
    Verifies the end-to-end evolution chain.
    
    In a full integration test, this would use actual LLM calls.
    For unit testing, we use MockLLM to simulate the chain.
    """
    
    def __init__(self, output_dir: str = None):
        """
        Initialize the verifier.
        
        Args:
            output_dir: Directory for test output files
        """
        self.output_dir = output_dir or tempfile.mkdtemp(prefix="love_e2e_test_")
        self.test_file_path = os.path.join(self.output_dir, "hello_world.py")
        self.expected_content = 'print("Hello World")'
        self.results = {
            "stack_initialized": False,
            "command_processed": False,
            "file_created": False,
            "content_verified": False,
            "cleanup_done": False
        }
    
    async def initialize_stack(self):
        """Initialize the DeepAgent stack with tool registry."""
        print("1. Initializing stack...")
        
        try:
            # In a full test, we'd initialize:
            # - ToolRegistry
            # - MemoryManager
            # - DeepAgentEngine
            
            # For this verification, we ensure imports work
            from core.tool_registry import ToolRegistry
            from core.tools import write_file, read_file
            
            self.results["stack_initialized"] = True
            print("   ‚úÖ Stack initialized")
            return True
            
        except Exception as e:
            print(f"   ‚ùå Stack initialization failed: {e}")
            return False
    
    async def process_command_with_mock(self):
        """
        Process the creation command using MockLLM.
        
        This simulates what the agent would do when given the command.
        """
        print(f'\n2. Sending command: "Create a file named hello_world.py"')
        
        try:
            # Create a mock LLM that returns a write_file tool call
            mock = MockLLM()
            mock.set_tool_call_response(
                tool_name="write_file",
                args={
                    "filepath": self.test_file_path,
                    "content": self.expected_content
                },
                pattern="create.*file"
            )
            
            # Simulate the reasoning process
            prompt = "Create a file named hello_world.py that prints Hello World"
            result = await mock.generate(prompt)
            response = result["result"]
            
            # Verify the mock returned a tool call
            assert "<tool_call>" in response, "Mock should return tool call"
            
            # Parse the tool call
            tool_calls = _parse_tool_calls_from_response(response)
            assert tool_calls and len(tool_calls) > 0, "Should parse tool call"
            
            tool_call = tool_calls[0]
            assert tool_call["name"] == "write_file", "Should call write_file"
            
            # Execute the tool (simulating tool node)
            filepath = tool_call["args"]["filepath"]
            content = tool_call["args"]["content"]
            
            # Ensure directory exists
            os.makedirs(os.path.dirname(filepath), exist_ok=True)
            
            # Write the file
            with open(filepath, 'w') as f:
                f.write(content)
            
            self.results["command_processed"] = True
            print("   ‚úÖ Command processed")
            return True
            
        except Exception as e:
            print(f"   ‚ùå Command processing failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def verify_file_creation(self):
        """Verify the file was created."""
        print(f"\n3. Verifying file creation...")
        
        if os.path.exists(self.test_file_path):
            self.results["file_created"] = True
            print(f"   ‚úÖ File exists: {self.test_file_path}")
            return True
        else:
            print(f"   ‚ùå File not found: {self.test_file_path}")
            return False
    
    async def verify_file_contents(self):
        """Verify the file contains the expected content."""
        print(f"\n4. Verifying file contents...")
        
        try:
            with open(self.test_file_path, 'r') as f:
                content = f.read().strip()
            
            if self.expected_content in content:
                self.results["content_verified"] = True
                print(f'   ‚úÖ File contains: {self.expected_content}')
                return True
            else:
                print(f'   ‚ùå Expected: {self.expected_content}')
                print(f'   ‚ùå Got: {content}')
                return False
                
        except Exception as e:
            print(f"   ‚ùå Could not read file: {e}")
            return False
    
    async def cleanup(self):
        """Clean up test artifacts."""
        print("\n5. Cleanup...")
        
        try:
            if os.path.exists(self.output_dir):
                shutil.rmtree(self.output_dir)
            self.results["cleanup_done"] = True
            print("   ‚úÖ Cleanup complete")
            return True
        except Exception as e:
            print(f"   ‚ùå Cleanup failed: {e}")
            return False
    
    async def run_full_verification(self) -> bool:
        """
        Run the complete E2E verification.
        
        Returns:
            True if all steps passed
        """
        print("=" * 50)
        print("End-to-End Evolution Chain Verification")
        print("=" * 50)
        
        all_passed = True
        
        all_passed &= await self.initialize_stack()
        all_passed &= await self.process_command_with_mock()
        all_passed &= await self.verify_file_creation()
        all_passed &= await self.verify_file_contents()
        await self.cleanup()  # Cleanup even if tests fail
        
        print("\n" + "=" * 50)
        if all_passed:
            print("üéâ E2E Evolution Chain Test PASSED!")
        else:
            print("‚ùå E2E Evolution Chain Test FAILED")
            print(f"Results: {self.results}")
        print("=" * 50)
        
        return all_passed


async def test_evolution_chain_with_actual_tool():
    """
    Test using the actual write_file tool from core.tools.
    
    This tests the tool infrastructure directly.
    """
    print("\n" + "=" * 50)
    print("Testing with Actual write_file Tool")
    print("=" * 50)
    
    output_dir = tempfile.mkdtemp(prefix="love_tool_test_")
    test_file = os.path.join(output_dir, "tool_test.py")
    content = 'print("Hello from tool!")'
    
    try:
        # Use the actual tool
        from core.tools import write_file
        
        print(f"\n1. Calling write_file tool...")
        result = write_file.invoke({"filepath": test_file, "content": content})
        print(f"   Tool result: {result}")
        
        print(f"\n2. Verifying file...")
        assert os.path.exists(test_file), "File should exist"
        print("   ‚úÖ File exists")
        
        with open(test_file, 'r') as f:
            actual = f.read()
        assert content in actual, "Content should match"
        print("   ‚úÖ Content verified")
        
        print("\nüéâ Tool verification PASSED!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Tool verification FAILED: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        # Cleanup
        if os.path.exists(output_dir):
            shutil.rmtree(output_dir)


async def main():
    """Run all E2E verifications."""
    
    # Test 1: Full chain with mock
    verifier = EvolutionChainVerifier()
    chain_passed = await verifier.run_full_verification()
    
    # Test 2: Direct tool test
    tool_passed = await test_evolution_chain_with_actual_tool()
    
    # Final summary
    print("\n" + "=" * 50)
    print("FINAL SUMMARY")
    print("=" * 50)
    print(f"E2E Chain Test: {'‚úÖ PASSED' if chain_passed else '‚ùå FAILED'}")
    print(f"Tool Test:      {'‚úÖ PASSED' if tool_passed else '‚ùå FAILED'}")
    
    return chain_passed and tool_passed


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
